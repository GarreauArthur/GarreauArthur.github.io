---
layout: post
title: "How machines learn [nn part 5]"
date: 2019-08-18
math: true
comments: true
tags:
  - machine learning
  - Mathematics
---

To be able to understand neural networks, one must understand the basic principles
of machine learning. Machine learning is a form of applied statistics focusing
on the use of computers to statistically estimate complicated functions.

Machine learning gives the ability to computer scientists and software engineers
to solve problems that are non-deterministic, inherently stochastic or are not
computable in reasonable amount of time or memory.

Instead to having to write a program with strict rules to solve a problem, we
design an algorithm that will learn to solve it.

But how do machines learn ? What does it even mean ? Mitchell (1997) provides a
definition for us:

> A computer program is said to learn from experience E with respect to some
> class of tasks T and performance measure P, if its performance at tasks in T,
> as measured by P, improves with experience E.

The **task T** is the problem we want to solve. Here's a list of such tasks

* classification: the goal is to find a function f that maps an input to a category
or a probability to be or not to be in a category \\(f:\mathbb{R}^n\rightarrow \left \{ 1,2,...,k \right \}\\)
* regression: \\(f:\mathbb{R}^n\rightarrow\mathbb{R}\\)
* transcriptiooon (text/speech recognition)
* Machine translation (seq to seq)
* Anomaly detection
* Synthesis & sampling
* Importation of missing values
* Denoising
* Density or probability mass function estimation, learn \\(p_{model}:\mathbb{R}^n\rightarrow\mathbb{R}\\)

The **performance measure P** is usually a numeric value computed by a function
that observes the output of the algorithm. This performance measure is specific
to the task. For example, in a classifaction task we can measure its accuray (the
proportion of correct outputs) or its error rate (the proportiong of incorrect
outputs). 

The **experience E** is the data that the learning algorithm look at to learn.

Depending on the experience and the task we can distinguish two type of learning
algorithms:

* unsupervised: try to discover information about the data
* supervised: try to learn to associate inputs with a label or known value.

--------------------------------------------------------------------------------

# notes from DL book


But how do machines learn ? What does it even mean ? Mitchell (1997) provides a
definition for us:

> A computer program is said to learn from experience E with respect to some
> class of tasks T and performance measure P, if its performance at tasks in T,
> as measured by P, improves with experience E.

## The task T

Machine learning tasks are usually described in terms of how the machine learning
systems should process an **example**. An **example** (\\(\mathbf{x}\\)) is a
collection (usually a vector) of **features** (\\(x_i\\)).

$$
\mathbf{x} \in \mathbb{R}^n, \mathbf{x} = \begin{bmatrix}
x_1\\ 
x_2\\ 
...\\ 
x_n
\end{bmatrix}
$$

Here's a list of tasks:

* classification: the goal is to find a function f that maps an input to a category
or a probability to be or not to be in a category \\(f:\mathbb{R}^n\rightarrow \left \{ 1,2,...,k \right \}\\)
* regression: \\(f:\mathbb{R}^n\rightarrow\mathbb{R}\\)
* transcriptiooon (text/speech recognition)
* Machine translation (seq to seq)
* Anomaly detection
* Synthesis & sampling
* Importation of missing values
* Denoising
* Density or probability mass function estimation, learn \\(p_{model}:\mathbb{R}^n\rightarrow\mathbb{R}\\)

Most of the tasks described above require the learning algorithm to at least
implicitly capture the structure of the probability distribution of the data
it has seen. It must know where examples cluster tightly and where they are
unlikely to occur. (density estimation explicitly capture that distribution).

## Performance measure P

We need a way too measure how well a computer program is doing on task in order
to make it better. This performance measure is specific to the task. For example,
in a classifaction task we can measure its accuray (the proportion of correct
outputs) or its error rate (the proportiong of incorrect outputs). 

## Experience E

Learning algorithms experience datasets. We usually want to learn the entire
probability distribution that generated the dataset. In ML we usually distinguish
2 types of learning algorithms depending of the experience. Unsupervised learning
algorithm try to learn \\(p(x)\\), while supervised learning algorithms learn
\\(p(y|x)\\)

\\( ... \\)


--------------------------------------------------------------------------------


## sources

* Mitchell, T.M. (1997). *Machine Learning*. McGraw-Hill, New York
* Ian Goodfellow, Yoshua Bengio, Aaron Courville (2016). *Deep Learning*. MIT Press